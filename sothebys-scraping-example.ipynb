{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of how scraping works\n",
    "\n",
    "The website we want to scrape is RM Sotheby's, one of the biggest car auction sites. Because the site is dynamically generated, BeautifulSoup library is not enough -  we have to use Selenium to access the page via a webdriver. For general introduction to the project, see [ReadMe](README.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "driver_path = \"driver/chromedriver.exe\"\n",
    "page_url = \"https://rmsothebys.com/en/search#/?SortBy=Default&SearchTerm=&Category=All%20Categories&IncludeWithdrawnLots=false&Auction=&OfferStatus=Results&AuctionYear=&Model=Model&Make=Make&FeaturedOnly=false&StillForSaleOnly=false&Collection=All%20Lots&WithoutReserveOnly=false&Day=All%20Days&CategoryTag=All%20Motor%20Vehicles&page=1&pageSize=200&ToYear=NaN&FromYear=NaN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's include some webdriver options to make the whole process faster by disabling images. We'll create a dictionary in case we want to add more options later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start the webdriver we provided and feed it the URL of the page we want to open. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\n",
    "driver.get(page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note, chromedriver included with this repository works with Chrome version 79, you can download the latest version [here](https://sites.google.com/a/chromium.org/chromedriver/home) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, I will use BeautifulSoup for scraping content because I had already used it before, but Selenium can also be used in the following steps.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon entering the site, there is a popup window asking us to sign up for a newsletter; we can close it by inspecting the element and copying it's xpath and using selenium's find_element_by_xpath method, then clicking on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_cls = driver.find_element_by_xpath('//*[@id=\"tailoredEmailModal\"]/div/div/button')\n",
    "btn_cls.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not neccessary to just scrap the page, it must be done if we want to click any buttons on the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform webscraping using BeautifulSoup, we have to identify the portion of the page we want to scrape and where are it's located in the HTML code. Taking a quick look at the page structure we find that each of the search results on site are nested in `search-result__caption` class. We'll call the element containing all of them a container. Let's access the fifth element of that container, e.g. the fifth search result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_container = html_soup.find_all('div', class_=\"search-result__caption\")\n",
    "search_result = result_container[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the first search result looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"search-result__caption\">\n",
       "<h5 class=\"heading-details--bolder ellipsis ng-binding\">\n",
       "                                    ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019\n",
       "                                </h5>\n",
       "<h5 class=\"heading-subtitle--bold line ng-binding\" ng-show=\"item.Lot\">\n",
       "                                    Lot 107\n",
       "                                </h5>\n",
       "<h5 class=\"heading-subtitle--bold line ng-hide\" ng-hide=\"item.Lot\">\n",
       "</h5>\n",
       "<p class=\"heading-subtitle--bold ng-binding\">2017 Jeep Wrangler Custom </p>\n",
       "<p>\n",
       "<span class=\"heading-subtitle--bold ng-binding\">Sold For $57,120</span><br/>\n",
       "<span class=\"heading-subtitle--bold ng-binding ng-hide\" ng-show=\"item.PreSaleEstimate.length &gt; 0\"></span><br/>\n",
       "<span class=\"heading-details--bolder ng-binding\"></span><br/>\n",
       "<span class=\"heading-details--bold ng-binding\"></span><br/>\n",
       "<span class=\"heading-details--bolder ng-binding ng-hide\" ng-show=\"item.CurrentBid\">\n",
       "                                        Current Bid: <br/>\n",
       "</span>\n",
       "<span class=\"heading-details--bolder ng-binding ng-hide\" ng-show=\"item.TimeLeft\">\n",
       "                                        Closing: <br/>\n",
       "</span>\n",
       "</p>\n",
       "<span class=\"heading-details--bolder search-result__bottom-left ng-binding\">RM | ONLINE ONLY</span>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily tell, where's the data we want to collect; let's access those elements by using find_all method with appropriate HTML tags and restricting the method's output to one element, by providing the order of occurence of the HTML tag within the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"heading-subtitle--bold ng-binding\">2017 Jeep Wrangler Custom </p>\n"
     ]
    }
   ],
   "source": [
    "car_info = search_result.find_all('p')[0]\n",
    "price = search_result.find_all('span')[0] #price can be found in the first span, on the \"0th\" position\n",
    "additional_info = search_result.find_all('span')[3]\n",
    "auction_type = search_result.find_all('span')[-1] #auction type can be found in the last span found, the \"-1st\" \n",
    "auction_location = search_result.find_all('h5')[0]\n",
    "\n",
    "print(car_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to obtain values that are of interest to us, but we are stuck with HTML code. To get rid of it, we'll use regular expressions. The following expression uses: \n",
    "* lookahead to determine characters preceding our pattern,\n",
    "* a capture group to make accessing our pattern easier,\n",
    "* lookbehind to determine characters following our pattern.\n",
    "\n",
    "Because re.search expects it's arguments to be a string, we need to convert our search results first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?<=\">)\\s*(.*)\\s*(?=</)'\n",
    "\n",
    "car_re = re.search(pattern, str(car_info), re.IGNORECASE).group(1)\n",
    "price_re = re.search(pattern, str(price), re.IGNORECASE).group(1)\n",
    "additional_info_re = re.search(pattern, str(additional_info), re.IGNORECASE).group(1)\n",
    "auct_type_re = re.search(pattern, str(auction_type), re.IGNORECASE).group(1)\n",
    "auct_loc_re = re.search(pattern, str(auction_location), re.IGNORECASE).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 Jeep Wrangler Custom  Sold For $57,120  RM | ONLINE ONLY ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019\n"
     ]
    }
   ],
   "source": [
    "print(car_re, price_re, additional_info_re, auct_type_re, auct_loc_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's close the webdriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions \n",
    "\n",
    "We have successfully scraped some data using Selenium and Beautifulsoup. Next step wolud be to automate the whole process for multiple web pages and save the data, enabling further analysis. To see the automation process, click [here](sothebys-scraping-automated.ipynb). To see the data cleaning process, click [here](sothebys-data-cleaning.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
