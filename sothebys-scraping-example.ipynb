{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of how scraping works\n",
    "\n",
    "The website we want to scrape is RM Sotheby's, one of the biggest car auction sites. Because the site is dynamically generated, BeautifulSoup library is not enough -  we have to use Selenium to access the page via a webdriver. For general introduction to the project, see [ReadMe](). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "driver_path = \"driver/chromedriver.exe\"\n",
    "page_url = \"https://rmsothebys.com/en/search#/?SortBy=Default&SearchTerm=&Category=All%20Categories&IncludeWithdrawnLots=false&Auction=&OfferStatus=Results&AuctionYear=&Model=Model&Make=Make&FeaturedOnly=false&StillForSaleOnly=false&Collection=All%20Lots&WithoutReserveOnly=false&Day=All%20Days&CategoryTag=All%20Motor%20Vehicles&page=1&pageSize=200&ToYear=NaN&FromYear=NaN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's include some webdriver options to make the whole process faster by disabling image loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start the webdriver we provided and feed it the URL of the page we want to open. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\n",
    "driver.get(page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, I will use BeautifulSoup because I had already used it before, but Selenium can also be used in the following steps.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform webscraping using BeautifulSoup, we have to identify the portion of the page we want to scrape and where are it's located in the HTML code. Taking a quick look at the page structure we find that each of the search results on site are nested in `search-result__caption` class. We'll call the element containing all of them a container. Let's access the fifth element of that container, e.g. the fifth search result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_container = html_soup.find_all('div', class_=\"search-result__caption\")\n",
    "search_result = result_container[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the fifth search result looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"search-result__caption\">\n",
       "<h5 class=\"heading-details--bolder ng-binding\">\n",
       "                                    AUBURN SPRING 2019 - LOT 5003\n",
       "                                </h5>\n",
       "<p class=\"heading-subtitle--bold ng-binding\">1971 Dnepr KMZ MV-750 </p>\n",
       "<p>\n",
       "<span class=\"heading-subtitle--bold ng-binding\">Sold For $3,410</span><br/>\n",
       "<span class=\"heading-subtitle--bold ng-binding ng-hide\" ng-show=\"item.PreSaleEstimate.length &gt; 0\"></span><br/>\n",
       "<span class=\"heading-details--bolder ng-binding\"></span><br/>\n",
       "<span class=\"heading-details--bolder ng-binding ng-hide\" ng-show=\"item.StyleClass == 'RMOnlineAuctions' &amp;&amp; item.CurrentBid\"><br/></span>\n",
       "<span class=\"heading-details--bolder ng-binding ng-hide\" ng-show=\"item.StyleClass == 'RMOnlineAuctions' &amp;&amp; item.TimeLeft\"><br/></span>\n",
       "</p>\n",
       "<span class=\"heading-details--bolder search-result__bottom-left ng-binding\">RM | AUCTIONS</span>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily tell, where's the data we want to collect, let's access those elements by using find_all method with appropriate HTML tags and restricting the method's output to one element, by providing the order of occurence of the HTML tag within the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"heading-subtitle--bold ng-binding\">Sold For $3,410</span>\n"
     ]
    }
   ],
   "source": [
    "car_info = search_result.find_all('p')[0]\n",
    "price = search_result.find_all('span')[0] #price can be found in the first span, on the \"0th\" position\n",
    "auction_type = search_result.find_all('span')[-1] #auction type can be found in the last span found, the \"-1st\" \n",
    "auction_location = search_result.find_all('h5')[0]\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to obtain values that are of interest to us, but we are stuck with HTML code. To get rid of it, we'll use regular expressions. The following expression uses: \n",
    "* lookahead to determine characters preceding our pattern,\n",
    "* a capture group to make accessing our pattern easier,\n",
    "* lookbehind to determine characters following our pattern.\n",
    "\n",
    "Because re.search expects it's arguments to be a string, we need to convert our search results first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?<=\">)\\s*(.*)\\s*(?=</)'\n",
    "\n",
    "car_re = re.search(pattern, str(car_info), re.IGNORECASE).group(1)\n",
    "price_re = re.search(pattern, str(price), re.IGNORECASE).group(1)\n",
    "auct_type_re = re.search(pattern, str(auction_type), re.IGNORECASE).group(1)\n",
    "auct_loc_re = re.search(pattern, str(auction_location), re.IGNORECASE).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971 Dnepr KMZ MV-750  Sold For $3,410 RM | AUCTIONS AUBURN SPRING 2019 - LOT 5003\n"
     ]
    }
   ],
   "source": [
    "print(car_re, price_re, auct_type_re, auct_loc_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's close the webdriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions \n",
    "\n",
    "We have successfully scraped some data using Selenium and Beautifulsoup. Next step wolud be to automate the whole process for multiple web pages and save the data, enabling further analysis. To see the automation process, click [here](). To see the data cleaning process, click [here]()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
