{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating the scraping process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are two ways to go about this:\n",
    "1. Get the search results, append them to one of the tables, construct a DataFrame object, change the types to String and then apply regular expressions to a DataFrame using vectorised methods or\n",
    "2. Get the search results, change the types to String, apply regular expressions, then append them to one ofthe tables and construct a DataFrame object.\n",
    "\n",
    "Common sense suggests, that the first approach would be better, but let's keep in mind, that the raw scrape results are long HTML tags, making everything really hard to read and spotting potential errors even harder. Measuring performance differences between the two approaches is currently not the scope of the project, but can be easily done using for example timeit module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "export_path = \"data/sothebys_scraped.csv\"\n",
    "driver_path = \"driver/chromedriver.exe\"\n",
    "page_url = \"https://rmsothebys.com/en/search#/?SortBy=Default&SearchTerm=&Category=All%20Categories&IncludeWithdrawnLots=false&Auction=&OfferStatus=Results&AuctionYear=&Model=Model&Make=Make&FeaturedOnly=false&StillForSaleOnly=false&Collection=All%20Lots&WithoutReserveOnly=false&Day=All%20Days&CategoryTag=All%20Motor%20Vehicles&page=1&pageSize=200&ToYear=NaN&FromYear=NaN\"\n",
    "num_of_pages = 5206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling image loading, to make the whole process faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "# chrome_options.add_argument('--ignore-certificate-errors')\n",
    "# chrome_options.add_argument('--incognito')\n",
    "# chrome_options.add_argument('--headless')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating tables that will hold our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_info_table = []\n",
    "price_table = []\n",
    "additional_info_table = []\n",
    "auction_type_table = []\n",
    "auction_location_table = []\n",
    "lot_table = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automating the process of scraping each of the web pages, for more detail and step by step guide to scraping elements of the web page, go [here](sothebys-scraping-example.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e93a300363a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mcar_re\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mprice_re\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0madditional_info_re\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madditional_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "#Pattern we will look for in HTML code\n",
    "pattern = r'(?<=\">)\\s*(.*)\\s*(?=</)'\n",
    "\n",
    "#Running the webdriver and loading our page\n",
    "driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\n",
    "driver.get(page_url)\n",
    "time.sleep(1)\n",
    "\n",
    "#Clicking the pop-up window when visiting the site for the first time\n",
    "driver.find_element_by_xpath('//*[@id=\"tailoredEmailModal\"]/div/div/button').click()\n",
    "\n",
    "for page_number in range(num_of_pages):\n",
    "    #Extracting page source from the driver\n",
    "    current_page_source = driver.find_element_by_xpath(\"//*\").get_attribute(\"outerHTML\")\n",
    "    html_page = BeautifulSoup(current_page_source)\n",
    "    result_container = html_page.find_all('div', class_=\"search-result__caption\")\n",
    "    \n",
    "    for result_number in range(len(result_container)):\n",
    "        search_result = result_container[result_number]\n",
    "                \n",
    "        car_info = search_result.find_all('p')[0]\n",
    "        price = search_result.find_all('span')[0] \n",
    "        additional_info = search_result.find_all('span')[3]\n",
    "        auction_type = search_result.find_all('span')[-1] \n",
    "        auction_location = search_result.find_all('h5')[0]\n",
    "        lot = search_result.find_all('h5')[1]\n",
    "\n",
    "        \n",
    "        car_re = re.search(pattern, str(car_info), re.IGNORECASE).group(1)\n",
    "        price_re = re.search(pattern, str(price), re.IGNORECASE).group(1)\n",
    "        additional_info_re = re.search(pattern, str(additional_info), re.IGNORECASE).group(1)\n",
    "        auct_type_re = re.search(pattern, str(auction_type), re.IGNORECASE).group(1)\n",
    "        auct_loc_re = re.search(pattern, str(auction_location), re.IGNORECASE).group(1)\n",
    "        lot_re = re.search(pattern, str(lot), re.IGNORECASE).group(1)\n",
    "        \n",
    "        car_info_table.append(car_re)\n",
    "        price_table.append(price_re)\n",
    "        additional_info_table.append(additional_info_re)\n",
    "        auction_type_table.append(auct_type_re)\n",
    "        auction_location_table.append(auct_loc_re)\n",
    "        lot_table.append(lot_re)\n",
    "    \n",
    "    #Clicking the next page button\n",
    "    driver.find_element_by_css_selector(\"a[ng-click='vm.setPage(vm.pager.currentPage + 1)']\").click() \n",
    "    #Delaying the next iteration by one second, it is needed for the page's source code to fully load\n",
    "    time.sleep(1)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the tables as a DataFrame object, preparing for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sothebys_df = pd.DataFrame({\"car_info\": car_info_table, \"price\": price_table,\n",
    "                            \"additional_info\": additional_info_table, \"auction_type\": auction_type_table, \n",
    "                            \"auction_location\": auction_location_table, \"lot\": lot_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_info</th>\n",
       "      <th>price</th>\n",
       "      <th>additional_info</th>\n",
       "      <th>auction_type</th>\n",
       "      <th>auction_location</th>\n",
       "      <th>lot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017 Jeep Wrangler Custom</td>\n",
       "      <td>Sold For $57,120</td>\n",
       "      <td></td>\n",
       "      <td>RM | ONLINE ONLY</td>\n",
       "      <td>ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019</td>\n",
       "      <td>Lot 107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1966 Austin-Healey 3000 Mk III BJ8</td>\n",
       "      <td>Sold For $58,240</td>\n",
       "      <td></td>\n",
       "      <td>RM | ONLINE ONLY</td>\n",
       "      <td>ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019</td>\n",
       "      <td>Lot 106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989 Ferrari Testarossa</td>\n",
       "      <td>Sold After Auction</td>\n",
       "      <td></td>\n",
       "      <td>RM | ONLINE ONLY</td>\n",
       "      <td>ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019</td>\n",
       "      <td>Lot 105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018 Audi SQ5</td>\n",
       "      <td>Sold For $42,560</td>\n",
       "      <td></td>\n",
       "      <td>RM | ONLINE ONLY</td>\n",
       "      <td>ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019</td>\n",
       "      <td>Lot 104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960 Austin-Healey 3000 Mk I BN7</td>\n",
       "      <td>Sold For $40,320</td>\n",
       "      <td></td>\n",
       "      <td>RM | ONLINE ONLY</td>\n",
       "      <td>ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019</td>\n",
       "      <td>Lot 103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006 Ford GT</td>\n",
       "      <td>Sold After Auction</td>\n",
       "      <td></td>\n",
       "      <td>RM | ONLINE ONLY</td>\n",
       "      <td>ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019</td>\n",
       "      <td>Lot 102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1967 Austin Mini Moke</td>\n",
       "      <td>Sold For $50,400</td>\n",
       "      <td></td>\n",
       "      <td>RM | ONLINE ONLY</td>\n",
       "      <td>ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019</td>\n",
       "      <td>Lot 101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              car_info               price additional_info  \\\n",
       "0           2017 Jeep Wrangler Custom     Sold For $57,120                   \n",
       "1  1966 Austin-Healey 3000 Mk III BJ8     Sold For $58,240                   \n",
       "2             1989 Ferrari Testarossa   Sold After Auction                   \n",
       "3                       2018 Audi SQ5     Sold For $42,560                   \n",
       "4    1960 Austin-Healey 3000 Mk I BN7     Sold For $40,320                   \n",
       "5                        2006 Ford GT   Sold After Auction                   \n",
       "6               1967 Austin Mini Moke     Sold For $50,400                   \n",
       "\n",
       "       auction_type                           auction_location      lot  \n",
       "0  RM | ONLINE ONLY  ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019  Lot 107  \n",
       "1  RM | ONLINE ONLY  ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019  Lot 106  \n",
       "2  RM | ONLINE ONLY  ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019  Lot 105  \n",
       "3  RM | ONLINE ONLY  ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019  Lot 104  \n",
       "4  RM | ONLINE ONLY  ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019  Lot 103  \n",
       "5  RM | ONLINE ONLY  ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019  Lot 102  \n",
       "6  RM | ONLINE ONLY  ONLINE ONLY: DRIVE INTO THE HOLIDAYS 2019  Lot 101  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sothebys_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inevitably, some records will be scrapped more than once, so let's remove duplicates before saving the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117394, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sothebys_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sothebys_df.drop_duplicates(keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34514, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sothebys_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to save the data as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported = sothebys_df.to_csv(export_path, index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "We have successfully scraped nearly 245.000 data points, from over 1200 web pages. Our dataset combining all the data, has more than 48.000 rows across 5 columns, making it ready for data cleaning and feature engineering process. To see the scraping process in detail, click [here](sothebys-scraping-example.ipynb). To see the data cleaning process, click [here](sothebys-data-cleaning.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
